{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "de639941",
      "metadata": {
        "id": "de639941",
        "papermill": {
          "duration": 0.015286,
          "end_time": "2024-11-15T01:55:41.934486",
          "exception": false,
          "start_time": "2024-11-15T01:55:41.919200",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<link rel=\"stylesheet\" href=\"/site-assets/css/gemma.css\">\n",
        "\n",
        "<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Google+Symbols:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "923d9f42",
      "metadata": {
        "id": "923d9f42",
        "papermill": {
          "duration": 0.01283,
          "end_time": "2024-11-15T01:55:41.960565",
          "exception": false,
          "start_time": "2024-11-15T01:55:41.947735",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aab6a6a4",
      "metadata": {
        "cellView": "form",
        "execution": {
          "iopub.execute_input": "2024-11-15T01:55:41.988820Z",
          "iopub.status.busy": "2024-11-15T01:55:41.988478Z",
          "iopub.status.idle": "2024-11-15T01:55:41.993634Z",
          "shell.execute_reply": "2024-11-15T01:55:41.992795Z"
        },
        "id": "aab6a6a4",
        "papermill": {
          "duration": 0.021383,
          "end_time": "2024-11-15T01:55:41.995543",
          "exception": false,
          "start_time": "2024-11-15T01:55:41.974160",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "\n",
        "# you may not use this file except in compliance with the License.\n",
        "\n",
        "# You may obtain a copy of the License at\n",
        "\n",
        "#\n",
        "\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "#\n",
        "\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "\n",
        "# See the License for the specific language governing permissions and\n",
        "\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f301e9b3",
      "metadata": {
        "id": "f301e9b3",
        "papermill": {
          "duration": 0.013261,
          "end_time": "2024-11-15T01:55:42.022010",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.008749",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "# Fine-tune Gemma models in Keras using LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a278b214",
      "metadata": {
        "id": "a278b214",
        "papermill": {
          "duration": 0.017369,
          "end_time": "2024-11-15T01:55:42.052524",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.035155",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "\n",
        "  <td>\n",
        "\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/gemma/docs/lora_tuning\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "\n",
        "  <td>\n",
        "\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "\n",
        "    <a target=\"_blank\" href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/google/generative-ai-docs/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://ai.google.dev/images/cloud-icon.svg\" width=\"40\" />Open in Vertex AI</a>\n",
        "\n",
        "  </td>\n",
        "\n",
        "  <td>\n",
        "\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/gemma/docs/lora_tuning.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "\n",
        "  </td>\n",
        "\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75abc932",
      "metadata": {
        "id": "75abc932",
        "papermill": {
          "duration": 0.012777,
          "end_time": "2024-11-15T01:55:42.078422",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.065645",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Overview\n",
        "\n",
        "\n",
        "\n",
        "Gemma is a family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models.\n",
        "\n",
        "\n",
        "\n",
        "Large Language Models (LLMs) like Gemma have been shown to be effective at a variety of NLP tasks. An LLM is first pre-trained on a large corpus of text in a self-supervised fashion. Pre-training helps LLMs learn general-purpose knowledge, such as statistical relationships between words. An LLM can then be fine-tuned with domain-specific data to perform downstream tasks (such as sentiment analysis).\n",
        "\n",
        "\n",
        "\n",
        "LLMs are extremely large in size (parameters in the order of billions). Full fine-tuning (which updates all the parameters in the model) is not required for most applications because typical fine-tuning datasets are relatively much smaller than the pre-training datasets.\n",
        "\n",
        "\n",
        "\n",
        "[Low Rank Adaptation (LoRA)](https://arxiv.org/abs/2106.09685) is a fine-tuning technique which greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. This makes training with LoRA much faster and more memory-efficient, and produces smaller model weights (a few hundred MBs), all while maintaining the quality of the model outputs.\n",
        "\n",
        "\n",
        "\n",
        "This tutorial walks you through using KerasNLP to perform LoRA fine-tuning on a Gemma 2B model using the [Databricks Dolly 15k dataset](https://huggingface.co/datasets/databricks/databricks-dolly-15k). This dataset contains 15,000 high-quality human-generated prompt / response pairs specifically designed for fine-tuning LLMs."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "662618b0",
      "metadata": {
        "id": "662618b0",
        "papermill": {
          "duration": 0.012853,
          "end_time": "2024-11-15T01:55:42.104414",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.091561",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "534aeaef",
      "metadata": {
        "id": "534aeaef",
        "papermill": {
          "duration": 0.012763,
          "end_time": "2024-11-15T01:55:42.130096",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.117333",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Get access to Gemma\n",
        "\n",
        "\n",
        "\n",
        "To complete this tutorial, you will first need to complete the setup instructions at [Gemma setup](https://ai.google.dev/gemma/docs/setup). The Gemma setup instructions show you how to do the following:\n",
        "\n",
        "\n",
        "\n",
        "* Get access to Gemma on [kaggle.com](https://kaggle.com).\n",
        "\n",
        "* Select a Colab runtime with sufficient resources to run\n",
        "\n",
        "  the Gemma 2B model.\n",
        "\n",
        "* Generate and configure a Kaggle username and API key.\n",
        "\n",
        "\n",
        "\n",
        "After you've completed the Gemma setup, move on to the next section, where you'll set environment variables for your Colab environment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f7541a",
      "metadata": {
        "id": "00f7541a",
        "papermill": {
          "duration": 0.012791,
          "end_time": "2024-11-15T01:55:42.155869",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.143078",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Select the runtime\n",
        "\n",
        "\n",
        "\n",
        "To complete this tutorial, you'll need to have a Colab runtime with sufficient resources to run the Gemma model. In this case, you can use a T4 GPU:\n",
        "\n",
        "\n",
        "\n",
        "1. In the upper-right of the Colab window, select &#9662; (**Additional connection options**).\n",
        "\n",
        "2. Select **Change runtime type**.\n",
        "\n",
        "3. Under **Hardware accelerator**, select **T4 GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b797bcf",
      "metadata": {
        "id": "1b797bcf",
        "papermill": {
          "duration": 0.012735,
          "end_time": "2024-11-15T01:55:42.181483",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.168748",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Configure your API key\n",
        "\n",
        "\n",
        "\n",
        "To use Gemma, you must provide your Kaggle username and a Kaggle API key.\n",
        "\n",
        "\n",
        "\n",
        "To generate a Kaggle API key, go to the **Account** tab of your Kaggle user profile and select **Create New Token**. This will trigger the download of a `kaggle.json` file containing your API credentials.\n",
        "\n",
        "\n",
        "\n",
        "In Colab, select **Secrets** (ğŸ”‘) in the left pane and add your Kaggle username and Kaggle API key. Store your username under the name `KAGGLE_USERNAME` and your API key under the name `KAGGLE_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2d597930",
      "metadata": {
        "id": "2d597930",
        "papermill": {
          "duration": 0.012842,
          "end_time": "2024-11-15T01:55:42.207496",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.194654",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Set environment variables\n",
        "\n",
        "\n",
        "\n",
        "Set environment variables for `KAGGLE_USERNAME` and `KAGGLE_KEY`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "174745f8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:55:42.235593Z",
          "iopub.status.busy": "2024-11-15T01:55:42.235267Z",
          "iopub.status.idle": "2024-11-15T01:55:55.094826Z",
          "shell.execute_reply": "2024-11-15T01:55:55.093562Z"
        },
        "id": "174745f8",
        "outputId": "6b1e02e4-74c0-42c3-e874-4d6aa52bd14a",
        "papermill": {
          "duration": 12.876634,
          "end_time": "2024-11-15T01:55:55.097126",
          "exception": false,
          "start_time": "2024-11-15T01:55:42.220492",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (3.3.3)\r\n",
            "Requirement already satisfied: keras-nlp in /opt/conda/lib/python3.10/site-packages (0.15.1)\r\n",
            "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.25.1)\r\n",
            "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.10/site-packages (2.16.1)\r\n",
            "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras) (1.4.0)\r\n",
            "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras) (1.26.4)\r\n",
            "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras) (13.7.1)\r\n",
            "Requirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras) (0.0.8)\r\n",
            "Requirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras) (3.11.0)\r\n",
            "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (from keras) (0.11.0)\r\n",
            "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.10/site-packages (from keras) (0.3.2)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (21.3)\r\n",
            "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2024.5.15)\r\n",
            "Requirement already satisfied: kagglehub in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (0.3.1)\r\n",
            "Requirement already satisfied: tensorflow-text in /opt/conda/lib/python3.10/site-packages (from keras-nlp) (2.16.1)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.15.1)\r\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2024.6.1)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.2)\r\n",
            "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.32.3)\r\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.4)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.12.2)\r\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.6.3)\r\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (24.3.25)\r\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.5.4)\r\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.2.0)\r\n",
            "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (18.1.1)\r\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.3.0)\r\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.20.3)\r\n",
            "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (70.0.0)\r\n",
            "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.4.0)\r\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\r\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.62.2)\r\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (2.16.2)\r\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (0.37.0)\r\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-nlp) (3.1.2)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.7)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.18)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2024.8.30)\r\n",
            "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\r\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\r\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.4)\r\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (3.0.0)\r\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras) (2.18.0)\r\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.5)\r\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install keras keras-nlp huggingface-hub tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b967678d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:55:55.128124Z",
          "iopub.status.busy": "2024-11-15T01:55:55.127772Z",
          "iopub.status.idle": "2024-11-15T01:55:55.132815Z",
          "shell.execute_reply": "2024-11-15T01:55:55.131922Z"
        },
        "id": "b967678d",
        "papermill": {
          "duration": 0.023075,
          "end_time": "2024-11-15T01:55:55.134850",
          "exception": false,
          "start_time": "2024-11-15T01:55:55.111775",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Set these directly if not using Colab; replace 'your_kaggle_username' and 'your_kaggle_key' with actual values\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"oluidiakhoa\"\n",
        "os.environ[\"KAGGLE_KEY\"] = \"6b8f69f428789daad475b6e04f03975e\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3a46108",
      "metadata": {
        "id": "c3a46108",
        "papermill": {
          "duration": 0.013955,
          "end_time": "2024-11-15T01:55:55.162998",
          "exception": false,
          "start_time": "2024-11-15T01:55:55.149043",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Install dependencies\n",
        "\n",
        "\n",
        "\n",
        "Install Keras, KerasNLP, and other dependencies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff68eb3a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:55:55.192978Z",
          "iopub.status.busy": "2024-11-15T01:55:55.192643Z",
          "iopub.status.idle": "2024-11-15T01:56:21.413803Z",
          "shell.execute_reply": "2024-11-15T01:56:21.412630Z"
        },
        "id": "ff68eb3a",
        "papermill": {
          "duration": 26.238859,
          "end_time": "2024-11-15T01:56:21.416063",
          "exception": false,
          "start_time": "2024-11-15T01:55:55.177204",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
        "\n",
        "!pip install -q -U keras-nlp\n",
        "\n",
        "!pip install -q -U \"keras>=3\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a377c34b",
      "metadata": {
        "id": "a377c34b",
        "papermill": {
          "duration": 0.013885,
          "end_time": "2024-11-15T01:56:21.444369",
          "exception": false,
          "start_time": "2024-11-15T01:56:21.430484",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Select a backend\n",
        "\n",
        "\n",
        "\n",
        "Keras is a high-level, multi-framework deep learning API designed for simplicity and ease of use. Using Keras 3, you can run workflows on one of three backends: TensorFlow, JAX, or PyTorch.\n",
        "\n",
        "\n",
        "\n",
        "For this tutorial, configure the backend for JAX."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0075d2ce",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:56:21.473387Z",
          "iopub.status.busy": "2024-11-15T01:56:21.473039Z",
          "iopub.status.idle": "2024-11-15T01:56:21.477836Z",
          "shell.execute_reply": "2024-11-15T01:56:21.476993Z"
        },
        "id": "0075d2ce",
        "papermill": {
          "duration": 0.02172,
          "end_time": "2024-11-15T01:56:21.479834",
          "exception": false,
          "start_time": "2024-11-15T01:56:21.458114",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"  # Or \"torch\" or \"tensorflow\".\n",
        "\n",
        "# Avoid memory fragmentation on JAX backend.\n",
        "\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"]=\"1.00\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ac6123",
      "metadata": {
        "id": "04ac6123",
        "papermill": {
          "duration": 0.013757,
          "end_time": "2024-11-15T01:56:21.507486",
          "exception": false,
          "start_time": "2024-11-15T01:56:21.493729",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Import packages\n",
        "\n",
        "\n",
        "\n",
        "Import Keras and KerasNLP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9d645d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:56:21.536423Z",
          "iopub.status.busy": "2024-11-15T01:56:21.536057Z",
          "iopub.status.idle": "2024-11-15T01:56:34.437164Z",
          "shell.execute_reply": "2024-11-15T01:56:34.436384Z"
        },
        "id": "e9d645d3",
        "papermill": {
          "duration": 12.918555,
          "end_time": "2024-11-15T01:56:34.439902",
          "exception": false,
          "start_time": "2024-11-15T01:56:21.521347",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "\n",
        "import keras_nlp"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5480d123",
      "metadata": {
        "id": "5480d123",
        "papermill": {
          "duration": 0.01386,
          "end_time": "2024-11-15T01:56:34.469332",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.455472",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59058318",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:56:34.499108Z",
          "iopub.status.busy": "2024-11-15T01:56:34.498590Z",
          "iopub.status.idle": "2024-11-15T01:56:34.502883Z",
          "shell.execute_reply": "2024-11-15T01:56:34.502012Z"
        },
        "id": "59058318",
        "papermill": {
          "duration": 0.021602,
          "end_time": "2024-11-15T01:56:34.504828",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.483226",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "##!wget -O databricks-dolly-15k.jsonl https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b70e02c",
      "metadata": {
        "id": "5b70e02c",
        "papermill": {
          "duration": 0.01376,
          "end_time": "2024-11-15T01:56:34.532511",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.518751",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Preprocess the data. This tutorial uses a subset of 1000 training examples to execute the notebook faster. Consider using more training data for higher quality fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e6c34d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:56:34.561818Z",
          "iopub.status.busy": "2024-11-15T01:56:34.561510Z",
          "iopub.status.idle": "2024-11-15T01:56:34.948330Z",
          "shell.execute_reply": "2024-11-15T01:56:34.947514Z"
        },
        "id": "0e6c34d8",
        "papermill": {
          "duration": 0.404012,
          "end_time": "2024-11-15T01:56:34.950632",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.546620",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "# Load and filter data\n",
        "data = []\n",
        "\n",
        "# Replace 'med_qa.jsonl' with the actual file name\n",
        "with open(\"/kaggle/input/med-dataset/formatted_data.jsonl\") as file:\n",
        "    for line in file:\n",
        "        features = json.loads(line)\n",
        "\n",
        "        # Filter out examples with context to keep it simple\n",
        "        if features[\"context\"]:\n",
        "            continue\n",
        "\n",
        "        # Format the entire example as a single string\n",
        "        template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "        data.append(template.format(**features))\n",
        "\n",
        "# Shuffle and limit to 1300 examples\n",
        "# random.shuffle(data)\n",
        "data = data[:3000]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c49a1c0",
      "metadata": {
        "id": "7c49a1c0",
        "papermill": {
          "duration": 0.01399,
          "end_time": "2024-11-15T01:56:34.979058",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.965068",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Load Model\n",
        "\n",
        "\n",
        "\n",
        "KerasNLP provides implementations of many popular [model architectures](https://keras.io/api/keras_nlp/models/). In this tutorial, you'll create a model using `GemmaCausalLM`, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
        "\n",
        "\n",
        "\n",
        "Create the model using the `from_preset` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e42c2a8f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:56:35.009031Z",
          "iopub.status.busy": "2024-11-15T01:56:35.008064Z",
          "iopub.status.idle": "2024-11-15T01:57:13.762367Z",
          "shell.execute_reply": "2024-11-15T01:57:13.761431Z"
        },
        "id": "e42c2a8f",
        "outputId": "7cd62e30-46fc-4029-8972-247bd268bad3",
        "papermill": {
          "duration": 38.771323,
          "end_time": "2024-11-15T01:57:13.764326",
          "exception": false,
          "start_time": "2024-11-15T01:56:34.993003",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,614,341,888\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
              "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma2/keras/gemma2_2b_en/1\")\n",
        "\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a76232",
      "metadata": {
        "id": "79a76232",
        "papermill": {
          "duration": 0.015167,
          "end_time": "2024-11-15T01:57:13.795488",
          "exception": false,
          "start_time": "2024-11-15T01:57:13.780321",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The `from_preset` method instantiates the model from a preset architecture and weights. In the code above, the string \"gemma2_2b_en\" specifies the preset architecture â€” a Gemma model with 2 billion parameters.\n",
        "\n",
        "\n",
        "\n",
        "NOTE: A Gemma model with 7\n",
        "\n",
        "billion parameters is also available. To run the larger model in Colab, you need access to the premium GPUs available in paid plans. Alternatively, you can perform [distributed tuning on a Gemma 7B model](https://ai.google.dev/gemma/docs/distributed_tuning) on Kaggle or Google Cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8504e5a8",
      "metadata": {
        "id": "8504e5a8",
        "papermill": {
          "duration": 0.014989,
          "end_time": "2024-11-15T01:57:13.826140",
          "exception": false,
          "start_time": "2024-11-15T01:57:13.811151",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Symptoms of Glaucoma Prompt\n",
        "\n",
        "\n",
        "\n",
        "Query the model for suggestions on what to do on a trip to Europe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be5009d9",
      "metadata": {
        "id": "be5009d9",
        "papermill": {
          "duration": 0.014901,
          "end_time": "2024-11-15T01:57:13.856174",
          "exception": false,
          "start_time": "2024-11-15T01:57:13.841273",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference before fine tuning\n",
        "\n",
        "\n",
        "\n",
        "In this section, you will query the model with various prompts to see how it responds."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada4ce9e",
      "metadata": {
        "id": "ada4ce9e",
        "papermill": {
          "duration": 0.015091,
          "end_time": "2024-11-15T01:57:13.886470",
          "exception": false,
          "start_time": "2024-11-15T01:57:13.871379",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Med Q & A  Prompt\n",
        "\n",
        "\n",
        "\n",
        "Prompt the model to explain photosynthesis in terms simple enough for a 5 year old child to understand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02f30563",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:57:13.918777Z",
          "iopub.status.busy": "2024-11-15T01:57:13.918439Z",
          "iopub.status.idle": "2024-11-15T01:57:36.466781Z",
          "shell.execute_reply": "2024-11-15T01:57:36.465633Z"
        },
        "id": "02f30563",
        "outputId": "ca0243e6-1c3d-4d5b-acee-c9c35789c325",
        "papermill": {
          "duration": 22.567022,
          "end_time": "2024-11-15T01:57:36.469018",
          "exception": false,
          "start_time": "2024-11-15T01:57:13.901996",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What common risk factors for Lymphocytic Choriomeningitis (LCMV) should be highlighted in patient education materials?\n",
            "\n",
            "Response:\n",
            "A) A history of travel to an area where the virus is endemic, especially to areas of Africa and South America, is the most significant risk factor in LCMV.\n",
            "B) Pregnant women and those with a compromised immune system are at risk for LCMV.\n",
            "C) LCMV is a rare infection that can cause a wide range of clinical symptoms, including meningitis.\n",
            "D) The incubation period for LCMV is typically two weeks, although it may vary depending on the patient's immune status.\n",
            "\n",
            "Rationale:\n",
            "The incubation period for LCMV is typically two weeks, although it may vary depending on the patient's immune status. Pregnant women and those with a compromised immune system are at risk for LCMV. The risk of infection is increased in areas where the virus is endemic, such as Africa and South America. LCMV can be transmitted through contact with infected urine or feces, as well as through contact with contaminated bedding or clothing. It can also be spread through contact with blood or other bodily fluids. Symptoms of LCMV may include fever, headache, nausea, vomiting, fatigue, and muscle pain.\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        " instruction=\"What common risk factors for Lymphocytic Choriomeningitis (LCMV) should be highlighted in patient education materials?\",\n",
        " response=\"\",\n",
        ")\n",
        "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler) # Removed extra spaces before this line\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7db449a4",
      "metadata": {
        "id": "7db449a4",
        "papermill": {
          "duration": 0.015433,
          "end_time": "2024-11-15T01:57:36.500810",
          "exception": false,
          "start_time": "2024-11-15T01:57:36.485377",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The model responds with generic tips on how to plan a trip."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e7ffedb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:57:36.534050Z",
          "iopub.status.busy": "2024-11-15T01:57:36.533153Z",
          "iopub.status.idle": "2024-11-15T01:57:44.447941Z",
          "shell.execute_reply": "2024-11-15T01:57:44.446859Z"
        },
        "id": "8e7ffedb",
        "outputId": "a0ad2e01-8fc4-40e5-b885-0134edfc3279",
        "papermill": {
          "duration": 7.933682,
          "end_time": "2024-11-15T01:57:44.450116",
          "exception": false,
          "start_time": "2024-11-15T01:57:36.516434",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the primary diagnostic steps for LCMV, and what challenges may arise in accurately diagnosing it?\n",
            "\n",
            "Response:\n",
            "Diagnostic steps:\n",
            "-Clinical presentation\n",
            "-Laboratory tests (CBC, serologic tests for LCMV, and serology for other viruses)\n",
            "-Viral cultures and viral RNA detection\n",
            "-Serologic tests are used in LCMV diagnosis, and they are also used to detect other viruses. Serologic tests may not be able to distinguish LCMV from other viruses that have similar symptoms.\n",
            "-Viral culture can detect LCMV, but it is not as sensitive as PCR testing, which can detect LCMV in the blood.\n",
            "-PCR testing can detect LCMV in the blood and may be the preferred method for LCMV diagnosis.\n",
            "\n",
            "Challenges:\n",
            "-LCMV infection can be difficult to distinguish from other viral infections.\n",
            "\n",
            "-The incubation period of LCMV can vary, and it can be difficult to determine the onset of symptoms in some cases.\n",
            "\n",
            "-LCMV can spread through direct contact, and it can be transmitted to people who have been exposed to an infected animal or person with the virus.\n",
            "\n",
            "-LCMV can be difficult to detect in some cases, and it may be necessary to use serologic tests in addition\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction to identify causes of sudden weight loss\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the primary diagnostic steps for LCMV, and what challenges may arise in accurately diagnosing it?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287d473d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:57:44.485704Z",
          "iopub.status.busy": "2024-11-15T01:57:44.485312Z",
          "iopub.status.idle": "2024-11-15T01:57:52.525170Z",
          "shell.execute_reply": "2024-11-15T01:57:52.524120Z"
        },
        "id": "287d473d",
        "outputId": "cc0c74f7-ffce-4925-ece6-fbfa948c706d",
        "papermill": {
          "duration": 8.060097,
          "end_time": "2024-11-15T01:57:52.527492",
          "exception": false,
          "start_time": "2024-11-15T01:57:44.467395",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What diagnostic tests are most effective in early detection of viral infections with neurological symptoms?\n",
            "\n",
            "Response:\n",
            "In the early stages of a viral infection, itâ€™s hard to determine which viruses are causing the symptoms. A physician may order a complete blood cell count (CBC). If there are abnormal results, a physician may order a viral panel, which is usually a combination of blood tests that screen for a wide variety of viruses, including HIV, cytomegalovirus, hepatitis, parvovirus, Epstein-Barr, and herpes simplex.\n",
            "\n",
            "The physician may also order an antibody test to detect the presence of viral antibodies. If a virus is present, the antibodies may be found in the blood, urine, or cerebro spinal fluid. If a virus is not present, the test will be negative.\n",
            "\n",
            "In some cases, the physician may order a viral culture. A culture of the virus is taken from the blood, urine, or cerebral spinal fluid. If there is no virus present, the culture will be negative.\n",
            "\n",
            "The physician may also order a PCR test. This test is used to detect viruses in the blood and urine. If a virus is present, the PCR will be positive.\n",
            "\n",
            "If the physician has not yet determined the cause of the symptoms,\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction about anemia and its treatment\n",
        "prompt = template.format(\n",
        "    instruction=\"What diagnostic tests are most effective in early detection of viral infections with neurological symptoms?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3a5fb91",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:57:52.560413Z",
          "iopub.status.busy": "2024-11-15T01:57:52.560055Z",
          "iopub.status.idle": "2024-11-15T01:58:00.405620Z",
          "shell.execute_reply": "2024-11-15T01:58:00.404550Z"
        },
        "id": "c3a5fb91",
        "outputId": "e1b361fa-d5a7-4731-a570-d2f7dff60b49",
        "papermill": {
          "duration": 7.86443,
          "end_time": "2024-11-15T01:58:00.407924",
          "exception": false,
          "start_time": "2024-11-15T01:57:52.543494",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the early symptoms of common zoonotic infections, and how can they be differentiated from similar diseases?\n",
            "\n",
            "Response:\n",
            "The early symptoms of common zoonotic infections can include fever, malaise, headache, muscle aches, diarrhea, nausea, vomiting, abdominal pain, rash, and other symptoms. These symptoms can be similar to those of other diseases, such as the flu, so it's important to consult a healthcare provider to rule out other causes.\n",
            "\n",
            "Differentiating between the early symptoms of common zoonotic infections and similar diseases can be challenging, but there are several key factors to consider.\n",
            "\n",
            "1. Duration of symptoms: The duration of symptoms can be a helpful guide. For example, many zoonotic infections have an incubation period of 2-10 days before symptoms appear, while other common infections, such as the flu, have a shorter incubation period of 1-3 days. This can help distinguish between acute infections that are caused by zoonotic pathogens and those that are caused by other viruses, such as the flu.\n",
            "2. Geographic location: The geographic location of the infection can be a helpful clue. Some zoonotic infections are more common in certain areas, such as rabies in areas where bats are abundant\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction on diagnosing chronic kidney disease\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the early symptoms of common zoonotic infections, and how can they be differentiated from similar diseases?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e610ed9a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:58:00.441446Z",
          "iopub.status.busy": "2024-11-15T01:58:00.441097Z",
          "iopub.status.idle": "2024-11-15T01:58:08.567373Z",
          "shell.execute_reply": "2024-11-15T01:58:08.566408Z"
        },
        "id": "e610ed9a",
        "outputId": "bcedfdf0-a56c-4774-c6c7-d78a8399919a",
        "papermill": {
          "duration": 8.145518,
          "end_time": "2024-11-15T01:58:08.569513",
          "exception": false,
          "start_time": "2024-11-15T01:58:00.423995",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the key considerations for managing viral infections in immunocompromised individuals?\n",
            "\n",
            "Response:\n",
            "Managing viral infections in immunocompromised individuals can be challenging due to the weakened immune system and the increased susceptibility to various viral diseases. Key considerations include:\n",
            "\n",
            "1. Identifying the specific viral infection: Determining the type and strain of the virus is crucial for appropriate management and treatment.\n",
            "\n",
            "2. Monitoring for complications: Immunocompromised individuals may experience complications such as sepsis, pneumonia, or encephalitis, so it is important to monitor vital signs, assess for signs of infection, and provide supportive care as needed.\n",
            "\n",
            "3. Vaccination: Immunosuppressive therapy may reduce the effectiveness of vaccines, so it is essential to consider vaccination schedules and recommendations for the specific viral infections.\n",
            "\n",
            "4. Infection control measures: Implementing strict infection control practices, such as personal protective equipment (PPE) and hand hygiene, is necessary to prevent the spread of infections.\n",
            "\n",
            "5. Supportive measures: Providing appropriate supportive measures such as oxygen therapy, intravenous fluids, and antibiotics as indicated by the specific viral infection.\n",
            "\n",
            "6. Collaboration with healthcare providers: Working closely with infectious disease specialists and medical professionals to develop a comprehensive plan of care tailored to the individual needs.\n",
            "\n",
            "7. Close monitoring and follow-up:\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction about the causes of acid reflux and heartburn\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the key considerations for managing viral infections in immunocompromised individuals?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c32e5f3b",
      "metadata": {
        "id": "c32e5f3b",
        "papermill": {
          "duration": 0.01576,
          "end_time": "2024-11-15T01:58:08.601550",
          "exception": false,
          "start_time": "2024-11-15T01:58:08.585790",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "The model response contains words that might not be easy to understand for a child such as chlorophyll."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0279f86b",
      "metadata": {
        "id": "0279f86b",
        "papermill": {
          "duration": 0.015533,
          "end_time": "2024-11-15T01:58:08.632927",
          "exception": false,
          "start_time": "2024-11-15T01:58:08.617394",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## LoRA Fine-tuning\n",
        "\n",
        "\n",
        "\n",
        "To get better responses from the model, fine-tune the model with Low Rank Adaptation (LoRA) using the Databricks Dolly 15k dataset.\n",
        "\n",
        "\n",
        "\n",
        "The LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n",
        "\n",
        "\n",
        "\n",
        "A higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation.\n",
        "\n",
        "\n",
        "\n",
        "This tutorial uses a LoRA rank of 4. In practice, begin with a relatively small rank (such as 4, 8, 16). This is computationally efficient for experimentation. Train your model with this rank and evaluate the performance improvement on your task. Gradually increase the rank in subsequent trials and see if that further boosts performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccc25d43",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:58:08.666356Z",
          "iopub.status.busy": "2024-11-15T01:58:08.665565Z",
          "iopub.status.idle": "2024-11-15T01:58:08.969579Z",
          "shell.execute_reply": "2024-11-15T01:58:08.968655Z"
        },
        "id": "ccc25d43",
        "outputId": "291dde67-e52b-4b5e-ba9d-11087c2c72d5",
        "papermill": {
          "duration": 0.32276,
          "end_time": "2024-11-15T01:58:08.971425",
          "exception": false,
          "start_time": "2024-11-15T01:58:08.648665",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                                                  </span>â”ƒ<span style=\"font-weight: bold\">                                   Config </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              â”‚                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              â”‚                      Vocab size: \u001b[38;5;34m256,000\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                  </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape              </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to               </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gemma_backbone                â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,620,199,168</span> â”‚ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               â”‚                           â”‚                 â”‚ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> â”‚ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         â”‚                           â”‚                 â”‚                            â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              â”‚               \u001b[38;5;34m0\u001b[0m â”‚ -                          â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ gemma_backbone                â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        â”‚   \u001b[38;5;34m2,620,199,168\u001b[0m â”‚ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        â”‚\n",
              "â”‚ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               â”‚                           â”‚                 â”‚ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ token_embedding               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      â”‚     \u001b[38;5;34m589,824,000\u001b[0m â”‚ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         â”‚                           â”‚                 â”‚                            â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,620,199,168</span> (9.76 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,620,199,168\u001b[0m (9.76 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,857,280</span> (22.34 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,857,280\u001b[0m (22.34 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Enable LoRA for the model and set the LoRA rank to 4.\n",
        "\n",
        "gemma_lm.backbone.enable_lora(rank=8)\n",
        "\n",
        "gemma_lm.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58500666",
      "metadata": {
        "id": "58500666",
        "papermill": {
          "duration": 0.016853,
          "end_time": "2024-11-15T01:58:09.005974",
          "exception": false,
          "start_time": "2024-11-15T01:58:08.989121",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "Note that enabling LoRA reduces the number of trainable parameters significantly (from 2.6 billion to 2.9 million)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "401b9024",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:58:09.041558Z",
          "iopub.status.busy": "2024-11-15T01:58:09.041195Z",
          "iopub.status.idle": "2024-11-15T01:58:09.045409Z",
          "shell.execute_reply": "2024-11-15T01:58:09.044499Z"
        },
        "id": "401b9024",
        "papermill": {
          "duration": 0.025457,
          "end_time": "2024-11-15T01:58:09.048407",
          "exception": false,
          "start_time": "2024-11-15T01:58:09.022950",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Uncomment the line below if you want to enable mixed precision training on GPUs\n",
        "\n",
        "#keras.mixed_precision.set_global_policy('mixed_bfloat16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea03a263",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T01:58:09.092304Z",
          "iopub.status.busy": "2024-11-15T01:58:09.091583Z",
          "iopub.status.idle": "2024-11-15T03:44:21.185455Z",
          "shell.execute_reply": "2024-11-15T03:44:21.184421Z"
        },
        "id": "ea03a263",
        "outputId": "f0e9c84e-a0c8-4132-d4f5-4bdab75bb433",
        "papermill": {
          "duration": 6372.115276,
          "end_time": "2024-11-15T03:44:21.187577",
          "exception": false,
          "start_time": "2024-11-15T01:58:09.072301",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1307s\u001b[0m 426ms/step - loss: 1.1003 - sparse_categorical_accuracy: 0.5921\n",
            "Epoch 2/5\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1281s\u001b[0m 420ms/step - loss: 0.9810 - sparse_categorical_accuracy: 0.6169\n",
            "Epoch 3/5\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1260s\u001b[0m 420ms/step - loss: 0.9405 - sparse_categorical_accuracy: 0.6316\n",
            "Epoch 4/5\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1260s\u001b[0m 420ms/step - loss: 0.9014 - sparse_categorical_accuracy: 0.6440\n",
            "Epoch 5/5\n",
            "\u001b[1m3000/3000\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1261s\u001b[0m 420ms/step - loss: 0.8631 - sparse_categorical_accuracy: 0.6547\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7de7482179d0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Limit the input sequence length to 256 (to control memory usage).\n",
        "\n",
        "gemma_lm.preprocessor.sequence_length = 256\n",
        "\n",
        "# Use AdamW (a common optimizer for transformer models).\n",
        "\n",
        "optimizer = keras.optimizers.AdamW(\n",
        "\n",
        "    learning_rate=5e-5,\n",
        "\n",
        "    weight_decay=0.01,\n",
        "\n",
        ")\n",
        "\n",
        "# Exclude layernorm and bias terms from decay.\n",
        "\n",
        "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
        "\n",
        "\n",
        "\n",
        "gemma_lm.compile(\n",
        "\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\n",
        "    optimizer=optimizer,\n",
        "\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "\n",
        ")\n",
        "\n",
        "gemma_lm.fit(data, epochs=5, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3edd972",
      "metadata": {
        "id": "c3edd972",
        "papermill": {
          "duration": 0.972458,
          "end_time": "2024-11-15T03:44:23.160112",
          "exception": false,
          "start_time": "2024-11-15T03:44:22.187654",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "### Note on mixed precision fine-tuning on NVIDIA GPUs\n",
        "\n",
        "\n",
        "\n",
        "Full precision is recommended for fine-tuning. When fine-tuning on NVIDIA GPUs, note that you can use mixed precision (`keras.mixed_precision.set_global_policy('mixed_bfloat16')`) to speed up training with minimal effect on training quality. Mixed precision fine-tuning does consume more memory so is useful only on larger GPUs.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "For inference, half-precision (`keras.config.set_floatx(\"bfloat16\")`) will work and save memory while mixed precision is not applicable."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf426c9b",
      "metadata": {
        "id": "cf426c9b",
        "papermill": {
          "duration": 0.955161,
          "end_time": "2024-11-15T03:44:25.119089",
          "exception": false,
          "start_time": "2024-11-15T03:44:24.163928",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference after fine-tuning\n",
        "\n",
        "After fine-tuning, responses follow the instruction provided in the prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69163666",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:44:27.084093Z",
          "iopub.status.busy": "2024-11-15T03:44:27.083705Z",
          "iopub.status.idle": "2024-11-15T03:44:46.269033Z",
          "shell.execute_reply": "2024-11-15T03:44:46.268078Z"
        },
        "id": "69163666",
        "papermill": {
          "duration": 20.143538,
          "end_time": "2024-11-15T03:44:46.271367",
          "exception": false,
          "start_time": "2024-11-15T03:44:26.127829",
          "status": "completed"
        },
        "tags": [],
        "outputId": "b04b1e74-7bf4-4bb6-c5d3-10b2e11d5d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What common risk factors for Lymphocytic Choriomeningitis (LCMV) should be highlighted in patient education materials?\n",
            "\n",
            "Response:\n",
            "Scientists are not sure how the virus spreads from infected mice to humans. However, it is thought that people can become infected by touching infected mice or their feces, by breathing in virus-filled particles in the air, and by getting infected through contact with urine and other fluids from infected rodents.\n"
          ]
        }
      ],
      "source": [
        "prompt = template.format(\n",
        " instruction=\"What common risk factors for Lymphocytic Choriomeningitis (LCMV) should be highlighted in patient education materials?\",\n",
        " response=\"\",\n",
        ")\n",
        "sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "gemma_lm.compile(sampler=sampler) # Removed extra spaces before this line\n",
        "print(gemma_lm.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be76548a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:44:48.229738Z",
          "iopub.status.busy": "2024-11-15T03:44:48.229344Z",
          "iopub.status.idle": "2024-11-15T03:44:57.561182Z",
          "shell.execute_reply": "2024-11-15T03:44:57.559890Z"
        },
        "id": "be76548a",
        "papermill": {
          "duration": 10.305502,
          "end_time": "2024-11-15T03:44:57.563816",
          "exception": false,
          "start_time": "2024-11-15T03:44:47.258314",
          "status": "completed"
        },
        "tags": [],
        "outputId": "cc394665-0521-49f0-99c7-ddb9e9fc75ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the primary diagnostic steps for LCMV, and what challenges may arise in accurately diagnosing it?\n",
            "\n",
            "Response:\n",
            "Tests that examine the urine and blood are used to test for LCMV. Tests that examine the urine and blood are also used to identify whether a person has antibodies (proof that the person has had a previous infection) against LCMV.\n",
            "                    \n",
            "        The tests used to detect and diagnose LCMV are:          \n",
            "                \n",
            "                    -   Urine immunoassay. The urine immunoassay is not used to diagnose LCMV in children younger than age 1. This test is used to diagnose LCMV infection and to monitor the effectiveness of antiviral treatment. This test is not available at all laboratories.     -   ELISA test for IgM antibodies to LCMV. The ELISA test for IgM antibody to LCMV can be used to diagnose acute LCMV infection. This test is not available at all laboratories.    -   ELISA test for IgG antibodies to LCMV.     -   PCR test for viral RNA (ribonucleic acid).     -   Virus culture of the blood.    \n",
            "                    \n",
            "                    In some instances, it may be difficult to distinguish LCMV infections from those caused by other viral or bacterial infections.    \n",
            "                    \n",
            "        Follow-\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction to identify causes of sudden weight loss\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the primary diagnostic steps for LCMV, and what challenges may arise in accurately diagnosing it?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24cdd037",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:44:59.505311Z",
          "iopub.status.busy": "2024-11-15T03:44:59.504475Z",
          "iopub.status.idle": "2024-11-15T03:45:08.749991Z",
          "shell.execute_reply": "2024-11-15T03:45:08.749052Z"
        },
        "id": "24cdd037",
        "papermill": {
          "duration": 10.183696,
          "end_time": "2024-11-15T03:45:08.752187",
          "exception": false,
          "start_time": "2024-11-15T03:44:58.568491",
          "status": "completed"
        },
        "tags": [],
        "outputId": "9c3a928d-9243-49bd-8537-ecf98f94cd36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the early symptoms of common zoonotic infections, and how can they be differentiated from similar diseases?\n",
            "\n",
            "Response:\n",
            "Most zoonotic infections have no signs or symptoms. Some people who become infected with a zoonotic agent will have flu-like symptoms, such as a fever or muscle aches.\n",
            "                \n",
            "The symptoms of zoonotic infections vary, depending on the specific pathogen that causes the infection. The following table shows some of the common zoonotic infections and the signs and symptoms they may cause.\n",
            "                \n",
            "     Sign and Symptoms of Zoonotic Infections   Infected person may have the following symptoms:          - Fever.     - Muscle aches.     - Headache.     - Sore throat.     - Nausea.     - Abdominal pain.     - Diarrhea.     - Rash.         Some zoonotic infections may cause more severe symptoms, such as:         - Coughing.     - Breathing problems (which can cause pneumonia).     - Eye problems, such as blindness.     - Confusion, weakness, or numbness.     - Hearing loss.     - Seizures.     - Chest pain.         If a pregnant woman becomes infected with a zoonotic infection, she may have miscarriage or premature delivery or her baby may have miscarriage\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction on diagnosing chronic kidney disease\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the early symptoms of common zoonotic infections, and how can they be differentiated from similar diseases?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1747b585",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:45:10.709338Z",
          "iopub.status.busy": "2024-11-15T03:45:10.708953Z",
          "iopub.status.idle": "2024-11-15T03:45:19.828261Z",
          "shell.execute_reply": "2024-11-15T03:45:19.827314Z"
        },
        "id": "1747b585",
        "papermill": {
          "duration": 10.074783,
          "end_time": "2024-11-15T03:45:19.830253",
          "exception": false,
          "start_time": "2024-11-15T03:45:09.755470",
          "status": "completed"
        },
        "tags": [],
        "outputId": "2e03ee7f-613d-46da-b73c-66bf48faf131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What diagnostic tests are most effective in early detection of viral infections with neurological symptoms?\n",
            "\n",
            "Response:\n",
            "Blood tests and spinal fluid tests are used to identify and diagnose viral infections with neurological symptoms.\n",
            "                    Blood tests. Blood tests are done to check for certain viruses and other substances in the blood. The following types of blood tests are used in the diagnosis of viral infections with neurological symptoms:         -   Antibody blood test (serologic test): This type of blood test checks for antibodies (proteins made by the immune system to fight infection) in the blood. The test detects antibodies that are made by the immune system in response to a certain virus. The results can indicate if a person has had a past infection with a certain virus and how recently the infection occurred.    -   Enzyme-linked immunosorbent assay (ELISA) test: This type of blood test can be done on a blood sample or a cerebrospinal fluid (CSF) sample. In an ELISA test, the blood sample is placed in a test plate and allowed to react with a substance from the virus. A substance from the virus that was detected during the blood test is attached to the test plate. The antibody in the blood sample reacts with the\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction about anemia and its treatment\n",
        "prompt = template.format(\n",
        "    instruction=\"What diagnostic tests are most effective in early detection of viral infections with neurological symptoms?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e0065a3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:45:21.754063Z",
          "iopub.status.busy": "2024-11-15T03:45:21.753671Z",
          "iopub.status.idle": "2024-11-15T03:45:31.326689Z",
          "shell.execute_reply": "2024-11-15T03:45:31.325704Z"
        },
        "id": "0e0065a3",
        "papermill": {
          "duration": 10.509302,
          "end_time": "2024-11-15T03:45:31.328941",
          "exception": false,
          "start_time": "2024-11-15T03:45:20.819639",
          "status": "completed"
        },
        "tags": [],
        "outputId": "799464e1-a023-49df-9ddb-5bab43cdd578"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Instruction:\n",
            "What are the key considerations for managing viral infections in immunocompromised individuals?\n",
            "\n",
            "Response:\n",
            "Key Points\n",
            "                    - Immunocompromised patients should be treated with antiviral drugs to prevent or treat viral infections.    - The following antiviral drugs are used to treat viral infections in immunocompromised patients:         -  Antiviral drugs are available for treatment of herpesviruses.        -  Antiviral drugs are available for treatment of human immunodeficiency virus (HIV) infection and cytomegalovirus (CMV) infection.        -  Antiviral drugs are available for treatment of varicella-zoster virus (VZV) infection.        - Other antiviral drugs may be available for treatment of certain viral infections in immunocompromised patients.        - Patients should have regular tests to look for signs of infection.    - This summary was updated on July 28, 2016.\n",
            "                \n",
            "                \n",
            "                    - Immunocompromised patients should be treated with antiviral drugs to prevent or treat viral infections.    - Immunocompromised people are at risk of developing severe infections. Antiviral drugs can treat or prevent these infections. The treatment of viral infections is different in immunocompromised patients than in healthy patients. Some antiviral drugs are only effective against specific types of viruses. Certain antiviral drugs can\n"
          ]
        }
      ],
      "source": [
        "# Define the prompt with an instruction about the causes of acid reflux and heartburn\n",
        "prompt = template.format(\n",
        "    instruction=\"What are the key considerations for managing viral infections in immunocompromised individuals?\",\n",
        "    response=\"\"\n",
        ")\n",
        "\n",
        "# Generate a response from the language model\n",
        "print(gemma_lm.generate(prompt, max_length=256))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75c3e249",
      "metadata": {
        "id": "75c3e249",
        "papermill": {
          "duration": 0.934466,
          "end_time": "2024-11-15T03:45:33.246136",
          "exception": false,
          "start_time": "2024-11-15T03:45:32.311670",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "#Saving My Finetuned Model to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d37c6d96",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-11-15T03:45:35.169462Z",
          "iopub.status.busy": "2024-11-15T03:45:35.168594Z",
          "iopub.status.idle": "2024-11-15T03:45:35.172930Z",
          "shell.execute_reply": "2024-11-15T03:45:35.172013Z"
        },
        "id": "d37c6d96",
        "papermill": {
          "duration": 0.941613,
          "end_time": "2024-11-15T03:45:35.174975",
          "exception": false,
          "start_time": "2024-11-15T03:45:34.233362",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Upload the preset to Hugging Face Hub\n",
        "\n",
        "#hf_uri = \"hf://mgbam/finetune_gemma2_2b_en_medical_qa\"\n",
        "\n",
        "\n",
        "\n",
        "# Try uploading without specifying argument names\n",
        "\n",
        "#keras_nlp.upload_preset(hf_uri, '/content/finetune_gemma2_2b_en_medical_qa')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "732738e5",
      "metadata": {
        "id": "732738e5",
        "papermill": {
          "duration": 0.930399,
          "end_time": "2024-11-15T03:45:37.086026",
          "exception": false,
          "start_time": "2024-11-15T03:45:36.155627",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Inference of my Finetuned Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bc9e860",
      "metadata": {
        "id": "6bc9e860",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#kaggle_username = \"oluidiakhoa\"\n",
        "\n",
        "\n",
        "\n",
        "# Construct the Kaggle URI for uploading the preset as a new model variant\n",
        "\n",
        "#kaggle_uri = f\"kaggle://{kaggle_username}/gemma/keras/finetune1_gemma2_2b_en_medical_qa\"\n",
        "\n",
        "#finetuned_model = keras_nlp.models.GemmaCausalLM.from_preset(kaggle_uri)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68ffc1b6",
      "metadata": {
        "id": "68ffc1b6",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#Define the prompt template\n",
        "\n",
        "#template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "\n",
        "\n",
        "#Format the example with an instruction for the model\n",
        "\n",
        "#prompt = template.format( instruction=\"What is the medical definition of 'myelodysplastic syndrome\", response=\"\" )\n",
        "\n",
        "\n",
        "\n",
        "#Set up a Top-K Sampler with k=5\n",
        "\n",
        "#sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "\n",
        "\n",
        "\n",
        "#Compile the fine-tuned model with the specified sampler\n",
        "\n",
        "#finetuned_model.compile(sampler=sampler)\n",
        "\n",
        "\n",
        "\n",
        "#Generate text based on the prompt with a maximum length of 256 tokens\n",
        "\n",
        "#print(finetuned_model.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5698bd8",
      "metadata": {
        "id": "c5698bd8",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Define the prompt template\n",
        "\n",
        "        # Format the entire example as a single string.\n",
        "\n",
        "#template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#prompt = template.format(\n",
        "\n",
        " #   instruction=\"What is the medical definition of 'myelodysplastic syndrome\",\n",
        "\n",
        " #   response=\"\",\n",
        "\n",
        "#)\n",
        "\n",
        "#sampler = keras_nlp.samplers.TopKSampler(k=5, seed=2)\n",
        "\n",
        "# Use the finetuned_model instead of gemma_lm for generation\n",
        "\n",
        "# finetuned_model.compile(sampler=sampler)\n",
        "\n",
        "#print(finetuned_model.generate(prompt, max_length=256))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62dc96d3",
      "metadata": {
        "id": "62dc96d3",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Ensure your validation data (x_val) is in text/string format.\n",
        "\n",
        "# For example, if x_val is currently numeric, replace it with appropriate text or tokenized sequences.\n",
        "\n",
        "\n",
        "\n",
        "# Sample x_val - ensure this is text or tokenized sequences\n",
        "\n",
        "# This is just an example; replace with your actual validation data.\n",
        "\n",
        "# Each entry in x_val should be a question or sentence for language model evaluation.\n",
        "\n",
        "\n",
        "\n",
        "#x_val = [\n",
        "\n",
        " #   \"How is chronic obstructive pulmonary disease (COPD) treated?\",\n",
        "\n",
        " #   \"What are the symptoms of epilepsy?\",\n",
        "\n",
        "  #  \"What is the cause of osteoarthritis?\"\n",
        "\n",
        "#]\n",
        "\n",
        "\n",
        "\n",
        "# Similarly, ensure y_val contains the appropriate labels in numeric form.\n",
        "\n",
        "# y_val should have the true labels corresponding to the predictions expected from gemma_lm.\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model using the chosen metric (e.g., perplexity).\n",
        "\n",
        "# Here, perplexity_value will provide an indication of the model's performance on x_val and y_val.\n",
        "\n",
        "\n",
        "\n",
        "# The following line calculates and prints the perplexity for the language model on the validation data.\n",
        "\n",
        "# Adjust batch_size as needed for your model and data size.\n",
        "\n",
        "# perplexity_value = gemma_lm.evaluate(x_val, y_val, batch_size=32)\n",
        "\n",
        "# print(\"Perplexity: \", perplexity_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a500eb07",
      "metadata": {
        "id": "a500eb07",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "\n",
        "\n",
        "# Generate predictions\n",
        "\n",
        "# predictions = gemma_lm.predict(x_val)\n",
        "\n",
        "\n",
        "\n",
        "# Assuming `y_val` contains true labels\n",
        "\n",
        "# precision = precision_score(y_val, predictions, average='weighted')\n",
        "\n",
        "# recall = recall_score(y_val, predictions, average='weighted')\n",
        "\n",
        "# f1 = f1_score(y_val, predictions, average='weighted')\n",
        "\n",
        "\n",
        "\n",
        "# print(f\"Precision: {precision}, Recall: {recall}, F1 Score: {f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33b63de1",
      "metadata": {
        "id": "33b63de1",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#loss, accuracy = gemma_lm.evaluate(x_val, y_val)\n",
        "\n",
        "#print(f\"Validation Loss: {loss}, Validation Accuracy: {accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89836dc4",
      "metadata": {
        "id": "89836dc4",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "#from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "\n",
        "\n",
        "#reference = \"This is the correct response.\"\n",
        "\n",
        "#generated = gemma_lm.generate(\"Provide a response\", max_length=256)\n",
        "\n",
        "#score = sentence_bleu([reference.split()], generated.split())\n",
        "\n",
        "#print(\"BLEU score: \", score)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcbd175e",
      "metadata": {
        "id": "bcbd175e",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "The model now recommends places to visit in Europe."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "256f1e34",
      "metadata": {
        "id": "256f1e34",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "The model now explains photosynthesis in simpler terms."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29e4b7ea",
      "metadata": {
        "id": "29e4b7ea",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "Note that for demonstration purposes, this tutorial fine-tunes the model on a small subset of the dataset for just one epoch and with a low LoRA rank value. To get better responses from the fine-tuned model, you can experiment with:\n",
        "\n",
        "\n",
        "\n",
        "1. Increasing the size of the fine-tuning dataset\n",
        "\n",
        "2. Training for more steps (epochs)\n",
        "\n",
        "3. Setting a higher LoRA rank\n",
        "\n",
        "4. Modifying the hyperparameter values such as `learning_rate` and `weight_decay`."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5752d4d",
      "metadata": {
        "id": "f5752d4d",
        "papermill": {
          "duration": null,
          "end_time": null,
          "exception": null,
          "start_time": null,
          "status": "pending"
        },
        "tags": []
      },
      "source": [
        "## Summary and next steps\n",
        "\n",
        "\n",
        "\n",
        "This tutorial covered LoRA fine-tuning on a Gemma model using KerasNLP. Check out the following docs next:\n",
        "\n",
        "\n",
        "\n",
        "* Learn how to [generate text with a Gemma model](https://ai.google.dev/gemma/docs/get_started).\n",
        "\n",
        "* Learn how to perform [distributed fine-tuning and inference on a Gemma model](https://ai.google.dev/gemma/docs/distributed_tuning).\n",
        "\n",
        "* Learn how to [use Gemma open models with Vertex AI](https://cloud.google.com/vertex-ai/docs/generative-ai/open-models/use-gemma).\n",
        "\n",
        "* Learn how to [fine-tune Gemma using KerasNLP and deploy to Vertex AI](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/model_garden/model_garden_gemma_kerasnlp_to_vertexai.ipynb)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6086017,
          "sourceId": 9906104,
          "sourceType": "datasetVersion"
        },
        {
          "isSourceIdPinned": true,
          "modelId": 78150,
          "modelInstanceId": 72244,
          "sourceId": 85984,
          "sourceType": "modelInstanceVersion"
        }
      ],
      "dockerImageVersionId": 30787,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 6609.290819,
      "end_time": "2024-11-15T03:45:48.398183",
      "environment_variables": {},
      "exception": true,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-11-15T01:55:39.107364",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}