{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne-6TZsKvHTi"
      },
      "outputs": [],
      "source": [
        "!pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "import keras_nlp\n",
        "from keras_nlp.models import GemmaCausalLM\n",
        "from keras_nlp.samplers import TopKSampler\n",
        "\n",
        "# Define the prompt template\n",
        "template = \"Instruction:\\n{instruction}\\n\\nResponse:\\n{response}\"\n",
        "\n",
        "# Load the model from the specified path\n",
        "model_path = \"/root/.cache/kagglehub/models/oluidiakhoa/bert/keras/finetuneolu_gemma2_c10/2\"\n",
        "finetuned_model = GemmaCausalLM.from_preset(model_path)\n",
        "\n",
        "# Set up a Top-K Sampler with k=5\n",
        "sampler = TopKSampler(k=5, seed=2)\n",
        "\n",
        "# Compile the fine-tuned model with the specified sampler\n",
        "finetuned_model.compile(sampler=sampler)\n",
        "\n",
        "# Define a function to generate responses\n",
        "def generate_response(instruction):\n",
        "    # Format the prompt based on the template\n",
        "    prompt = template.format(instruction=instruction, response=\"\")\n",
        "    # Generate text with a maximum length of 256 tokens\n",
        "    response = finetuned_model.generate(prompt, max_length=256)\n",
        "    return response\n",
        "\n",
        "# Create a Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=generate_response,  # The function to call when input is provided\n",
        "    inputs=\"text\",         # Input type is a text field\n",
        "    outputs=\"text\",        # Output type is also text\n",
        "    title=\"Medical Language Model - Symptom Checker\",\n",
        "    description=\"Enter a medical question or instruction, and the model will respond with relevant information.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio app\n",
        "interface.launch()\n"
      ]
    }
  ]
}